{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import TensorBoard\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from skfeature.function.similarity_based import fisher_score\n",
    "from skfeature.function.similarity_based.fisher_score import fisher_score, feature_ranking\n",
    "from sklearn.metrics import recall_score, accuracy_score, precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fisher score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fisherScore(n_features, df):\n",
    "    benign = df[df[\"anomaly\"]==0].sample(n=1000, random_state=17)\n",
    "    malicious = df[df[\"anomaly\"]==1].sample(n=1000, random_state=17)\n",
    "    temp_df = pd.concat([benign, malicious])\n",
    "    score = fisher_score(temp_df.iloc[:, :-1].values, temp_df.iloc[:, -1].values)\n",
    "    ranked_features = list(feature_ranking(score))\n",
    "    ranked_features.append(n_features)\n",
    "    return ranked_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_order = fisherScore(115, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Prep**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_df = df[df[\"anomaly\"]==0].iloc[:, idx_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = np.split(benign_df.sample(frac=1, random_state=42), [int(1/3*len(benign_df)), int(2/3*len(benign_df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled = scaler.fit_transform(train.iloc[:, :-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_scaled = scaler.fit_transform(validate.iloc[:, :-1].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_encoder(input_dim):\n",
    "    autoencoder = Sequential()\n",
    "    autoencoder.add(Dense(int(0.75 * input_dim), activation=\"relu\", input_shape=(input_dim,)))\n",
    "    autoencoder.add(Dense(int(0.5 * input_dim), activation=\"relu\"))\n",
    "    autoencoder.add(Dense(int(0.33 * input_dim), activation=\"relu\"))\n",
    "    autoencoder.add(Dense(int(0.25 * input_dim), activation=\"relu\"))\n",
    "    autoencoder.add(Dense(int(0.33 * input_dim), activation=\"relu\"))\n",
    "    autoencoder.add(Dense(int(0.5 * input_dim), activation=\"relu\"))\n",
    "    autoencoder.add(Dense(int(0.75 * input_dim), activation=\"relu\"))\n",
    "    autoencoder.add(Dense(input_dim))\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = auto_encoder(115)\n",
    "trained_model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "tensorBoard = TensorBoard(log_dir=f\"./logs\", histogram_freq=0, write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "185310/185310 [==============================] - 5s 29us/step - loss: 0.0427\n",
      "Epoch 2/60\n",
      "185310/185310 [==============================] - 3s 18us/step - loss: 0.0423\n",
      "Epoch 3/60\n",
      "185310/185310 [==============================] - 3s 18us/step - loss: 0.0420\n",
      "Epoch 4/60\n",
      "185310/185310 [==============================] - 4s 20us/step - loss: 0.0415\n",
      "Epoch 5/60\n",
      "185310/185310 [==============================] - 4s 19us/step - loss: 0.0413\n",
      "Epoch 6/60\n",
      "185310/185310 [==============================] - 4s 20us/step - loss: 0.0408\n",
      "Epoch 7/60\n",
      "185310/185310 [==============================] - 3s 19us/step - loss: 0.0405\n",
      "Epoch 8/60\n",
      "185310/185310 [==============================] - 4s 21us/step - loss: 0.0401\n",
      "Epoch 9/60\n",
      "185310/185310 [==============================] - 4s 20us/step - loss: 0.0398\n",
      "Epoch 10/60\n",
      "185310/185310 [==============================] - 4s 22us/step - loss: 0.0395\n",
      "Epoch 11/60\n",
      "185310/185310 [==============================] - 4s 21us/step - loss: 0.0392\n",
      "Epoch 12/60\n",
      "185310/185310 [==============================] - 4s 21us/step - loss: 0.0388\n",
      "Epoch 13/60\n",
      "185310/185310 [==============================] - 5s 27us/step - loss: 0.0385\n",
      "Epoch 14/60\n",
      "185310/185310 [==============================] - 6s 31us/step - loss: 0.0382\n",
      "Epoch 15/60\n",
      "185310/185310 [==============================] - 4s 24us/step - loss: 0.0379\n",
      "Epoch 16/60\n",
      "185310/185310 [==============================] - 4s 23us/step - loss: 0.0376\n",
      "Epoch 17/60\n",
      "185310/185310 [==============================] - 4s 22us/step - loss: 0.0373\n",
      "Epoch 18/60\n",
      "185310/185310 [==============================] - 4s 22us/step - loss: 0.0370\n",
      "Epoch 19/60\n",
      "185310/185310 [==============================] - 4s 24us/step - loss: 0.0367\n",
      "Epoch 20/60\n",
      "185310/185310 [==============================] - 4s 24us/step - loss: 0.0364\n",
      "Epoch 21/60\n",
      "185310/185310 [==============================] - 4s 22us/step - loss: 0.0361\n",
      "Epoch 22/60\n",
      "185310/185310 [==============================] - 4s 24us/step - loss: 0.0359\n",
      "Epoch 23/60\n",
      "185310/185310 [==============================] - 5s 29us/step - loss: 0.0356\n",
      "Epoch 24/60\n",
      "185310/185310 [==============================] - 6s 31us/step - loss: 0.0353\n",
      "Epoch 25/60\n",
      "185310/185310 [==============================] - 6s 30us/step - loss: 0.0351\n",
      "Epoch 26/60\n",
      "185310/185310 [==============================] - 6s 32us/step - loss: 0.0348\n",
      "Epoch 27/60\n",
      "185310/185310 [==============================] - 5s 29us/step - loss: 0.0346\n",
      "Epoch 28/60\n",
      "185310/185310 [==============================] - 5s 29us/step - loss: 0.0343: 0s -\n",
      "Epoch 29/60\n",
      "185310/185310 [==============================] - 5s 29us/step - loss: 0.0341\n",
      "Epoch 30/60\n",
      "185310/185310 [==============================] - 5s 25us/step - loss: 0.0339\n",
      "Epoch 31/60\n",
      "185310/185310 [==============================] - 5s 25us/step - loss: 0.0336\n",
      "Epoch 32/60\n",
      "185310/185310 [==============================] - 5s 26us/step - loss: 0.0334\n",
      "Epoch 33/60\n",
      "185310/185310 [==============================] - 5s 28us/step - loss: 0.0332\n",
      "Epoch 34/60\n",
      "185310/185310 [==============================] - 6s 30us/step - loss: 0.0330\n",
      "Epoch 35/60\n",
      "185310/185310 [==============================] - 5s 26us/step - loss: 0.0328\n",
      "Epoch 36/60\n",
      "185310/185310 [==============================] - 5s 27us/step - loss: 0.0326\n",
      "Epoch 37/60\n",
      "185310/185310 [==============================] - 4s 23us/step - loss: 0.0323: 0s - loss: 0.032\n",
      "Epoch 38/60\n",
      "185310/185310 [==============================] - 5s 24us/step - loss: 0.0321\n",
      "Epoch 39/60\n",
      "185310/185310 [==============================] - 5s 25us/step - loss: 0.0320\n",
      "Epoch 40/60\n",
      "185310/185310 [==============================] - 5s 25us/step - loss: 0.0318\n",
      "Epoch 41/60\n",
      "185310/185310 [==============================] - 5s 28us/step - loss: 0.0316\n",
      "Epoch 42/60\n",
      "185310/185310 [==============================] - 3s 19us/step - loss: 0.0314\n",
      "Epoch 43/60\n",
      "185310/185310 [==============================] - 5s 25us/step - loss: 0.0312\n",
      "Epoch 44/60\n",
      "185310/185310 [==============================] - 5s 27us/step - loss: 0.0310\n",
      "Epoch 45/60\n",
      "185310/185310 [==============================] - 5s 25us/step - loss: 0.0309\n",
      "Epoch 46/60\n",
      "185310/185310 [==============================] - 5s 25us/step - loss: 0.0307\n",
      "Epoch 47/60\n",
      "185310/185310 [==============================] - 5s 27us/step - loss: 0.0305\n",
      "Epoch 48/60\n",
      "185310/185310 [==============================] - 4s 24us/step - loss: 0.0303\n",
      "Epoch 49/60\n",
      "185310/185310 [==============================] - 4s 20us/step - loss: 0.0302\n",
      "Epoch 50/60\n",
      "185310/185310 [==============================] - 4s 20us/step - loss: 0.0300\n",
      "Epoch 51/60\n",
      "185310/185310 [==============================] - 3s 19us/step - loss: 0.0298\n",
      "Epoch 52/60\n",
      "185310/185310 [==============================] - 3s 19us/step - loss: 0.0297\n",
      "Epoch 53/60\n",
      "185310/185310 [==============================] - 4s 19us/step - loss: 0.0295: 0s - loss: 0.029\n",
      "Epoch 54/60\n",
      "185310/185310 [==============================] - 4s 20us/step - loss: 0.0294\n",
      "Epoch 55/60\n",
      "185310/185310 [==============================] - 4s 20us/step - loss: 0.0292\n",
      "Epoch 56/60\n",
      "185310/185310 [==============================] - 4s 20us/step - loss: 0.0291\n",
      "Epoch 57/60\n",
      "185310/185310 [==============================] - 4s 19us/step - loss: 0.0289\n",
      "Epoch 58/60\n",
      "185310/185310 [==============================] - 3s 18us/step - loss: 0.0287\n",
      "Epoch 59/60\n",
      "185310/185310 [==============================] - 3s 18us/step - loss: 0.0286\n",
      "Epoch 60/60\n",
      "185310/185310 [==============================] - 3s 18us/step - loss: 0.0284\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a37529208>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model.fit(train_scaled, \n",
    "                  train_scaled, \n",
    "                  epochs=60, \n",
    "                  batch_size=100, \n",
    "                  verbose=1,\n",
    "                  callbacks=[tensorBoard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_validate_predictions = trained_model.predict(validate_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = np.mean(np.power(validate_scaled - x_validate_predictions, 2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = mse.mean() + mse.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.concat([test, df[df[\"anomaly\"]==1]], sort=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_set.iloc[:, idx_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_scaled = scaler.transform(test_set.iloc[:, :-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = trained_model.predict(test_set_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = np.mean(np.power(test_set_scaled - test_pred, 2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (mse > tr).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "0.9723076380504838\n",
      "Recall\n",
      "1.0\n",
      "Precision\n",
      "0.9723076380504838\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy')\n",
    "print(accuracy_score(test_set.iloc[:, -1], predictions))\n",
    "print('Recall')\n",
    "print(recall_score(test_set.iloc[:, -1], predictions))\n",
    "print('Precision')\n",
    "print(precision_score(test_set.iloc[:, -1], predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
